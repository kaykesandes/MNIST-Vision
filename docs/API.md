# üìö API Reference - Refer√™ncia das Fun√ß√µes

## üìã √çndice
- [Classe Modelo](#classe-modelo)
- [Fun√ß√µes de Visualiza√ß√£o](#fun√ß√µes-de-visualiza√ß√£o)
- [Fun√ß√µes de Treinamento](#fun√ß√µes-de-treinamento)
- [Utilit√°rios](#utilit√°rios)
- [Exemplos de Uso](#exemplos-de-uso)

## üß† Classe Modelo

### `class Modelo(nn.Module)`

Implementa uma rede neural feedforward para classifica√ß√£o MNIST.

#### **Construtor**

```python
Modelo()
```

**Descri√ß√£o:** Inicializa a arquitetura da rede neural.

**Par√¢metros:** Nenhum

**Atributos:**
- `linear1`: `nn.Linear(784, 128)` - Primeira camada
- `linear2`: `nn.Linear(128, 64)` - Segunda camada  
- `linear3`: `nn.Linear(64, 10)` - Camada de sa√≠da

**Exemplo:**
```python
modelo = Modelo()
print(f"Par√¢metros: {sum(p.numel() for p in modelo.parameters())}")
```

#### **M√©todo forward**

```python
forward(X: torch.Tensor) -> torch.Tensor
```

**Descri√ß√£o:** Executa propaga√ß√£o direta na rede neural.

**Par√¢metros:**
- `X` (`torch.Tensor`): Tensor de entrada com shape `[batch_size, 784]`

**Retorna:**
- `torch.Tensor`: Log-probabilidades com shape `[batch_size, 10]`

**Exemplo:**
```python
imagem = torch.randn(1, 784)
output = modelo(imagem)
probabilidades = torch.exp(output)  # Converter log-probs para probs
```

## üé® Fun√ß√µes de Visualiza√ß√£o

### `visualizar_predicoes_navegacao()`

```python
visualizar_predicoes_navegacao(
    modelo: nn.Module,
    dataloader: DataLoader,
    device: torch.device,
    num_amostras: int = 6,
    batch_idx: int = 0
) -> int
```

**Descri√ß√£o:** Cria visualiza√ß√£o interativa das predi√ß√µes com capacidade de navega√ß√£o entre batches.

**Par√¢metros:**
- `modelo` (`nn.Module`): Modelo neural treinado
- `dataloader` (`DataLoader`): Carregador de dados para visualiza√ß√£o
- `device` (`torch.device`): Dispositivo de processamento (CPU/GPU)
- `num_amostras` (`int`, opcional): N√∫mero de imagens a mostrar (padr√£o: 6)
- `batch_idx` (`int`, opcional): √çndice do batch a visualizar (padr√£o: 0)

**Retorna:**
- `int`: N√∫mero total de batches dispon√≠veis para navega√ß√£o

**Exce√ß√µes:**
- `IndexError`: Se `batch_idx` for inv√°lido (√© tratado automaticamente)

**Exemplo:**
```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
total_batches = visualizar_predicoes_navegacao(modelo, valloader, device, 8, 2)
print(f"Total de batches dispon√≠veis: {total_batches}")
```

### `forward_nextview()`

```python
forward_nextview(
    modelo: nn.Module,
    dataloader: DataLoader,
    device: torch.device,
    num_sequences: int = 3
) -> None
```

**Descri√ß√£o:** Mostra sequ√™ncias detalhadas de forward passes com an√°lise de probabilidades.

**Par√¢metros:**
- `modelo` (`nn.Module`): Modelo neural para an√°lise
- `dataloader` (`DataLoader`): Fonte de dados
- `device` (`torch.device`): Dispositivo de processamento
- `num_sequences` (`int`, opcional): N√∫mero de sequ√™ncias a mostrar (padr√£o: 3)

**Retorna:** `None`

**Comportamento:**
- Mostra 4 imagens por sequ√™ncia
- Pausa entre sequ√™ncias aguardando input do usu√°rio
- Exibe top-3 predi√ß√µes com probabilidades

**Exemplo:**
```python
# Demonstra√ß√£o com 5 sequ√™ncias
forward_nextview(modelo, trainloader, device, 5)
```

### `navegacao_interativa()`

```python
navegacao_interativa(
    modelo: nn.Module,
    dataloader: DataLoader,
    device: torch.device
) -> None
```

**Descri√ß√£o:** Interface de linha de comando para navega√ß√£o interativa entre predi√ß√µes.

**Par√¢metros:**
- `modelo` (`nn.Module`): Modelo neural para predi√ß√µes
- `dataloader` (`DataLoader`): Dados para visualiza√ß√£o
- `device` (`torch.device`): Dispositivo de processamento

**Retorna:** `None`

**Comandos Aceitos:**
- `'next'`, `'n'`: Pr√≥ximo batch
- `'prev'`, `'p'`: Batch anterior
- `'quit'`, `'q'`, `'exit'`: Sair da navega√ß√£o

**Exemplo:**
```python
# Inicia navega√ß√£o interativa
navegacao_interativa(modelo, valloader, device)
```

## üéì Fun√ß√µes de Treinamento

### `treino_com_visualizacao()`

```python
treino_com_visualizacao(
    modelo: nn.Module,
    trainloader: DataLoader,
    valloader: DataLoader,
    device: torch.device
) -> None
```

**Descri√ß√£o:** Executa treinamento completo do modelo com visualiza√ß√£o em tempo real.

**Par√¢metros:**
- `modelo` (`nn.Module`): Modelo a ser treinado
- `trainloader` (`DataLoader`): Dados de treinamento
- `valloader` (`DataLoader`): Dados de valida√ß√£o
- `device` (`torch.device`): Dispositivo de processamento

**Retorna:** `None`

**Configura√ß√£o Interna:**
```python
# Otimizador
otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)

# Fun√ß√£o de perda
criterios = nn.NLLLoss()

# Hyperpar√¢metros
EPOCHS = 3
```

**Visualiza√ß√µes Geradas:**
- Progress durante treinamento (a cada 300 batches)
- Gr√°ficos de perda e precis√£o por epoch
- Forward NextView durante o processo

**Exemplo:**
```python
# Treinar modelo com visualiza√ß√£o completa
treino_com_visualizacao(modelo, trainloader, valloader, device)
```

### `calcular_precisao()`

```python
calcular_precisao(
    modelo: nn.Module,
    valloader: DataLoader,
    device: torch.device
) -> float
```

**Descri√ß√£o:** Calcula precis√£o do modelo no dataset de valida√ß√£o.

**Par√¢metros:**
- `modelo` (`nn.Module`): Modelo a ser avaliado
- `valloader` (`DataLoader`): Dados de valida√ß√£o
- `device` (`torch.device`): Dispositivo de processamento

**Retorna:**
- `float`: Precis√£o como porcentagem (0-100)

**F√≥rmula:**
```
Precis√£o = (Predi√ß√µes Corretas / Total de Amostras) √ó 100
```

**Comportamento:**
- Coloca modelo em modo de avalia√ß√£o (`model.eval()`)
- Desabilita gradientes com `torch.no_grad()`
- Restaura modo de treinamento ao final

**Exemplo:**
```python
precisao = calcular_precisao(modelo, valloader, device)
print(f"Precis√£o do modelo: {precisao:.2f}%")
```

## üõ†Ô∏è Utilit√°rios

### Configura√ß√£o do Dataset

```python
# Transforma√ß√£o padr√£o
transform = transforms.ToTensor()

# Dataset de treino
trainset = datasets.MNIST(
    './MNIST_data/',
    download=True,
    train=True,
    transform=transform
)

# Dataset de valida√ß√£o
valset = datasets.MNIST(
    './MNIST_data/',
    download=True,
    train=False,
    transform=transform
)
```

### Configura√ß√£o de DataLoaders

```python
# DataLoader de treino
trainloader = torch.utils.data.DataLoader(
    trainset,
    batch_size=64,
    shuffle=True
)

# DataLoader de valida√ß√£o
valloader = torch.utils.data.DataLoader(
    valset,
    batch_size=64,
    shuffle=True
)
```

### Configura√ß√£o de Device

```python
# Detec√ß√£o autom√°tica CPU/GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Mover modelo para device
modelo.to(device)
```

## üìù Exemplos de Uso

### **Exemplo 1: Uso B√°sico Completo**

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms

# 1. Configura√ß√£o
transform = transforms.ToTensor()
trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)
valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)

# 2. Modelo e device
modelo = Modelo()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
modelo.to(device)

# 3. Treinamento
treino_com_visualizacao(modelo, trainloader, valloader, device)

# 4. Avalia√ß√£o
precisao = calcular_precisao(modelo, valloader, device)
print(f"Precis√£o final: {precisao:.2f}%")

# 5. Visualiza√ß√£o interativa
navegacao_interativa(modelo, valloader, device)
```

### **Exemplo 2: Predi√ß√£o em Nova Imagem**

```python
# Carregar imagem personalizada
def predizer_imagem(modelo, imagem_path, device):
    from PIL import Image
    
    # Carregar e preprocessar
    imagem = Image.open(imagem_path).convert('L')  # Escala de cinza
    imagem = imagem.resize((28, 28))
    transform = transforms.ToTensor()
    tensor_imagem = transform(imagem).unsqueeze(0)  # Adicionar batch dimension
    
    # Predi√ß√£o
    modelo.eval()
    with torch.no_grad():
        tensor_imagem = tensor_imagem.view(1, -1)  # Achatar
        output = modelo(tensor_imagem.to(device))
        probabilidades = torch.exp(output)
        predicao = torch.argmax(probabilidades, dim=1)
        confianca = torch.max(probabilidades)
    
    return predicao.item(), confianca.item()

# Usar
digito, confianca = predizer_imagem(modelo, 'meu_digito.png', device)
print(f"Predi√ß√£o: {digito} (confian√ßa: {confianca*100:.1f}%)")
```

### **Exemplo 3: Avalia√ß√£o Detalhada**

```python
def avaliacao_completa(modelo, dataloader, device):
    """Avalia√ß√£o detalhada com m√©tricas por classe"""
    modelo.eval()
    
    # Coletar todas as predi√ß√µes
    todas_predicoes = []
    todas_etiquetas = []
    
    with torch.no_grad():
        for imagens, etiquetas in dataloader:
            imagens = imagens.view(imagens.shape[0], -1)
            output = modelo(imagens.to(device))
            _, predicoes = torch.max(output, 1)
            
            todas_predicoes.extend(predicoes.cpu().numpy())
            todas_etiquetas.extend(etiquetas.numpy())
    
    # Calcular precis√£o por classe
    from collections import defaultdict
    precisao_por_classe = defaultdict(lambda: {'corretas': 0, 'total': 0})
    
    for pred, real in zip(todas_predicoes, todas_etiquetas):
        precisao_por_classe[real]['total'] += 1
        if pred == real:
            precisao_por_classe[real]['corretas'] += 1
    
    # Relat√≥rio
    print("=== RELAT√ìRIO DE AVALIA√á√ÉO ===")
    for classe in range(10):
        corretas = precisao_por_classe[classe]['corretas']
        total = precisao_por_classe[classe]['total']
        precisao = (corretas / total) * 100 if total > 0 else 0
        print(f"D√≠gito {classe}: {precisao:.1f}% ({corretas}/{total})")
    
    # Precis√£o geral
    total_corretas = sum(precisao_por_classe[i]['corretas'] for i in range(10))
    total_amostras = sum(precisao_por_classe[i]['total'] for i in range(10))
    precisao_geral = (total_corretas / total_amostras) * 100
    print(f"\nPrecis√£o Geral: {precisao_geral:.2f}%")

# Usar
avaliacao_completa(modelo, valloader, device)
```

### **Exemplo 4: Salvar e Carregar Modelo**

```python
# Salvar modelo treinado
def salvar_modelo(modelo, caminho='modelo_mnist.pth'):
    torch.save({
        'model_state_dict': modelo.state_dict(),
        'arquitetura': 'feedforward_784_128_64_10',
        'precisao': calcular_precisao(modelo, valloader, device)
    }, caminho)
    print(f"Modelo salvo em {caminho}")

# Carregar modelo
def carregar_modelo(caminho='modelo_mnist.pth'):
    checkpoint = torch.load(caminho)
    modelo = Modelo()
    modelo.load_state_dict(checkpoint['model_state_dict'])
    print(f"Modelo carregado. Precis√£o anterior: {checkpoint['precisao']:.2f}%")
    return modelo

# Usar
salvar_modelo(modelo)
modelo_carregado = carregar_modelo()
```

## üîß Configura√ß√µes Avan√ßadas

### **Personalizar Hyperpar√¢metros**

```python
def treino_personalizado(modelo, trainloader, valloader, device, config):
    """Treinamento com configura√ß√µes personalizadas"""
    
    # Configura√ß√µes
    lr = config.get('learning_rate', 0.01)
    momentum = config.get('momentum', 0.5)
    epochs = config.get('epochs', 3)
    
    # Otimizador
    otimizador = optim.SGD(modelo.parameters(), lr=lr, momentum=momentum)
    criterios = nn.NLLLoss()
    
    # Treinamento
    for epoch in range(epochs):
        for imagens, etiquetas in trainloader:
            imagens = imagens.view(imagens.shape[0], -1)
            otimizador.zero_grad()
            
            output = modelo(imagens.to(device))
            loss = criterios(output, etiquetas.to(device))
            
            loss.backward()
            otimizador.step()

# Usar
config = {
    'learning_rate': 0.1,
    'momentum': 0.9,
    'epochs': 5
}
treino_personalizado(modelo, trainloader, valloader, device, config)
```

---

**üìö Esta API reference fornece todas as informa√ß√µes necess√°rias para usar e estender o projeto MNIST!**
