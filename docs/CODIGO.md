# üìã Documenta√ß√£o T√©cnica do C√≥digo

## üìö √çndice
- [Vis√£o Geral](#vis√£o-geral)
- [Estrutura das Classes](#estrutura-das-classes)
- [Fun√ß√µes Principais](#fun√ß√µes-principais)
- [Fluxo de Dados](#fluxo-de-dados)
- [Implementa√ß√£o Detalhada](#implementa√ß√£o-detalhada)

## üéØ Vis√£o Geral

Este documento fornece uma explica√ß√£o t√©cnica detalhada de cada componente do c√≥digo, incluindo classes, fun√ß√µes, e o fluxo de execu√ß√£o completo.

## üèóÔ∏è Estrutura das Classes

### `class Modelo(nn.Module)`

**Prop√≥sito:** Implementa uma rede neural feedforward para classifica√ß√£o de d√≠gitos MNIST.

```python
class Modelo(nn.Module):
    def __init__(self):
        super(Modelo, self).__init__()
        self.linear1 = nn.Linear(28*28, 128)  # Camada de entrada
        self.linear2 = nn.Linear(128, 64)     # Camada oculta
        self.linear3 = nn.Linear(64, 10)      # Camada de sa√≠da
```

#### üìä Especifica√ß√µes:
- **Entrada:** 784 neur√¥nios (28√ó28 pixels achatados)
- **Camada 1:** 784 ‚Üí 128 neur√¥nios + ReLU
- **Camada 2:** 128 ‚Üí 64 neur√¥nios + ReLU
- **Sa√≠da:** 64 ‚Üí 10 neur√¥nios (classes 0-9) + LogSoftmax

#### ‚ö° M√©todo `forward(X)`:
```python
def forward(self, X):
    X = F.relu(self.linear1(X))    # Ativa√ß√£o ReLU na camada 1
    X = F.relu(self.linear2(X))    # Ativa√ß√£o ReLU na camada 2
    X = self.linear3(X)            # Camada final (sem ativa√ß√£o)
    return F.log_softmax(X, dim=1) # LogSoftmax para classifica√ß√£o
```

**Fluxo de Dados:**
```
Input [64, 784] ‚Üí Linear1 ‚Üí ReLU ‚Üí [64, 128] ‚Üí Linear2 ‚Üí ReLU ‚Üí [64, 64] ‚Üí Linear3 ‚Üí [64, 10] ‚Üí LogSoftmax
```

## üîß Fun√ß√µes Principais

### 1. `visualizar_predicoes_navegacao()`

**Prop√≥sito:** Cria visualiza√ß√£o interativa das predi√ß√µes com navega√ß√£o entre batches.

```python
def visualizar_predicoes_navegacao(modelo, dataloader, device, num_amostras=6, batch_idx=0):
```

#### üìù Par√¢metros:
| Par√¢metro | Tipo | Descri√ß√£o |
|-----------|------|-----------|
| `modelo` | `nn.Module` | Rede neural treinada |
| `dataloader` | `DataLoader` | Carregador de dados |
| `device` | `torch.device` | CPU ou GPU |
| `num_amostras` | `int` | N√∫mero de imagens a mostrar (padr√£o: 6) |
| `batch_idx` | `int` | √çndice do batch atual |

#### üîÑ Processo de Execu√ß√£o:

1. **Coleta de Batches:**
```python
all_batches = []
dataiter = iter(dataloader)
for i in range(5):  # Coleta 5 batches para navega√ß√£o
    try:
        batch = next(dataiter)
        all_batches.append(batch)
    except StopIteration:
        break
```

2. **Sele√ß√£o Aleat√≥ria:**
```python
indices = random.sample(range(len(imagens)), min(num_amostras, len(imagens)))
```

3. **Forward Pass e An√°lise:**
```python
output = modelo(imagem.to(device))
probabilidades = F.softmax(output, dim=1)
top3_prob, top3_pred = torch.topk(probabilidades, 3)
```

4. **Visualiza√ß√£o:**
```python
cor = 'green' if predicao_principal == etiqueta_real else 'red'
axes[i].set_title(titulo, color=cor, fontweight='bold')
```

### 2. `navegacao_interativa()`

**Prop√≥sito:** Interface de linha de comando para navegar entre predi√ß√µes.

#### üéÆ Comandos Aceitos:
- `next`, `n` ‚Üí Pr√≥ximo batch
- `prev`, `p` ‚Üí Batch anterior  
- `quit`, `q`, `exit` ‚Üí Sair

#### üîÑ Loop Principal:
```python
while True:
    total_batches = visualizar_predicoes_navegacao(modelo, dataloader, device, 6, batch_atual)
    comando = input(f"\nComando (next/prev/quit) [Batch {batch_atual+1}/{total_batches}]: ")
    
    if comando in ['next', 'n']:
        batch_atual = (batch_atual + 1) % total_batches  # Navega√ß√£o circular
    # ... outros comandos
```

### 3. `forward_nextview()`

**Prop√≥sito:** Demonstra sequ√™ncias detalhadas de forward passes.

#### üé¨ Caracter√≠sticas:
- Mostra 4 imagens por sequ√™ncia
- An√°lise completa de probabilidades
- Top-3 predi√ß√µes com percentuais
- Pausa interativa entre sequ√™ncias

#### üìä An√°lise de Probabilidades:
```python
probs = probabilidades.cpu().numpy()[0]  # Todas as 10 probabilidades
predicao = np.argmax(probs)              # Classe com maior probabilidade
top3_idx = np.argsort(probs)[-3:][::-1]  # √çndices das 3 maiores
```

### 4. `treino_com_visualizacao()`

**Prop√≥sito:** Fun√ß√£o principal de treinamento com feedback visual.

#### ‚öôÔ∏è Configura√ß√£o:
```python
otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)
criterios = nn.NLLLoss()
EPOCHS = 3
```

#### üîÑ Loop de Treinamento:
```python
for epoch in range(EPOCHS):
    for imagens, etiquetas in trainloader:
        # 1. Prepara√ß√£o dos dados
        imagens = imagens.view(imagens.shape[0], -1)
        
        # 2. Forward pass
        output = modelo(imagens.to(device))
        perda_instantanea = criterios(output, etiquetas.to(device))
        
        # 3. Backward pass
        otimizador.zero_grad()
        perda_instantanea.backward()
        otimizador.step()
        
        # 4. Visualiza√ß√£o peri√≥dica
        if batches_processados % 300 == 0:
            forward_nextview(modelo, valloader, device, 1)
```

#### üìà M√©tricas Coletadas:
- **Perda por √©poca:** `historico_perdas.append(perda_media)`
- **Precis√£o por √©poca:** `historico_precisao.append(precisao)`

### 5. `calcular_precisao()`

**Prop√≥sito:** Calcula precis√£o do modelo no dataset de valida√ß√£o.

#### üìä F√≥rmula:
```
Precis√£o = (Predi√ß√µes Corretas / Total de Amostras) √ó 100
```

#### üîç Implementa√ß√£o:
```python
with torch.no_grad():  # Desabilita gradientes para economia de mem√≥ria
    for imagens, etiquetas in valloader:
        output = modelo(imagens.to(device))
        _, predicted = torch.max(output.data, 1)  # Argmax das predi√ß√µes
        
        conta_todas += etiquetas.size(0)
        conta_corretas += (predicted.cpu() == etiquetas).sum().item()
```

## üìä Fluxo de Dados

### 1. **Prepara√ß√£o dos Dados:**
```
MNIST Raw ‚Üí transforms.ToTensor() ‚Üí DataLoader ‚Üí Batch[64, 1, 28, 28]
```

### 2. **Preprocessamento:**
```
Batch[64, 1, 28, 28] ‚Üí view(-1, 784) ‚Üí Batch[64, 784]
```

### 3. **Forward Pass:**
```
Input[64, 784] ‚Üí Modelo ‚Üí Output[64, 10] ‚Üí LogSoftmax ‚Üí Probabilidades
```

### 4. **Loss Calculation:**
```
LogProbs[64, 10] + Labels[64] ‚Üí NLLLoss ‚Üí Scalar Loss
```

### 5. **Backward Pass:**
```
Loss.backward() ‚Üí Gradientes ‚Üí Optimizer.step() ‚Üí Par√¢metros Atualizados
```

## üîç Implementa√ß√£o Detalhada

### üß† Forward Pass Explicado:

#### Camada 1:
```python
# Input: [batch_size, 784]
x1 = self.linear1(x)    # [batch_size, 128]
x1 = F.relu(x1)         # Aplica ReLU: max(0, x)
```

#### Camada 2:
```python
# Input: [batch_size, 128]  
x2 = self.linear2(x1)   # [batch_size, 64]
x2 = F.relu(x2)         # Aplica ReLU
```

#### Camada de Sa√≠da:
```python
# Input: [batch_size, 64]
x3 = self.linear3(x2)           # [batch_size, 10]
output = F.log_softmax(x3, dim=1)  # Log-probabilidades
```

### üìä An√°lise de Probabilidades:

#### Convers√£o para Probabilidades:
```python
log_probs = modelo(input)           # Log-probabilidades
probs = F.softmax(log_probs, dim=1) # Probabilidades reais (0-1)
```

#### Top-K Predi√ß√µes:
```python
top3_prob, top3_pred = torch.topk(probs, 3)
# top3_prob: [batch_size, 3] - probabilidades
# top3_pred: [batch_size, 3] - √≠ndices das classes
```

### üé® Sistema de Visualiza√ß√£o:

#### Configura√ß√£o de Plots:
```python
fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # Grid 2x3
axes = axes.ravel()  # Transforma em array 1D
```

#### Colora√ß√£o Condicional:
```python
cor = 'green' if predicao == etiqueta_real else 'red'
axes[i].set_title(titulo, color=cor, fontweight='bold')
```

#### Formata√ß√£o de T√≠tulos:
```python
titulo = f'Real: {etiqueta_real} | Pred: {predicao_principal}\n'
titulo += f'Top3: {top3_pred[0]}({top3_prob[0]*100:.1f}%) '
titulo += f'{top3_pred[1]}({top3_prob[1]*100:.1f}%) '
titulo += f'{top3_pred[2]}({top3_prob[2]*100:.1f}%)'
```

## ‚ö° Otimiza√ß√µes Implementadas

### 1. **Economia de Mem√≥ria:**
```python
with torch.no_grad():  # Desabilita autograd durante avalia√ß√£o
    # C√≥digo de infer√™ncia
```

### 2. **Gest√£o de Dispositivos:**
```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
modelo.to(device)
dados.to(device)
```

### 3. **Processamento em Batches:**
```python
batch_size = 64  # Processa 64 imagens simultaneamente
```

### 4. **Opera√ß√µes Vetorizadas:**
```python
# Evita loops Python, usa opera√ß√µes tensor otimizadas
output = modelo(batch_input)  # Processa todo o batch de uma vez
```

## üêõ Valida√ß√µes e Tratamento de Erros

### 1. **Valida√ß√£o de √çndices:**
```python
if batch_idx >= len(all_batches):
    batch_idx = 0  # Reset para o primeiro batch
```

### 2. **Tratamento de StopIteration:**
```python
try:
    batch = next(dataiter)
except StopIteration:
    dataiter = iter(dataloader)  # Reinicia o iterador
    batch = next(dataiter)
```

### 3. **Valida√ß√£o de Comandos:**
```python
if comando in ['next', 'n']:
    # Comando v√°lido
elif comando in ['prev', 'p']:
    # Comando v√°lido  
else:
    print("‚ùå Comando inv√°lido!")  # Feedback para usu√°rio
```

## üìà M√©tricas de Performance

### Complexidade Computacional:
- **Forward Pass:** O(batch_size √ó num_parameters)
- **Backward Pass:** O(batch_size √ó num_parameters)
- **Memory Usage:** ~50MB para modelo + dados

### Tempo de Execu√ß√£o:
- **Por Epoch:** ~30-60 segundos (CPU)
- **Forward Pass:** ~1ms por batch
- **Visualiza√ß√£o:** ~2-3 segundos por plot

---

**üìù Nota:** Este documento detalha a implementa√ß√£o t√©cnica. Para conceitos de machine learning, consulte [COMO_FUNCIONA.md](COMO_FUNCIONA.md).
